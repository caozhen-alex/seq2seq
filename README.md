# seq2seq
seq2seq model with attention mechanism.

### Preprocessing:
`python preprocessing.py`

### Training:
`python main.py`